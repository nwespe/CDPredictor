{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Setups -- Connecting Python and SQL\n",
    "\n",
    "The purpose of this Jupyter notebook is to demonstrate the usefulness of connecting python to a relational database by using a python toolkit called SQLAlchemy. This tutorial follows the previous document, *** Python and Data Science stack. ***\n",
    "\n",
    "***Note! The commands below were written for Python 2. Small adjustments will need to be made to some (i.e. Print statements) in Python 3.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***First off, what is a relational database?***\n",
    "\n",
    "Basically, it is a way to store data such that information can be retrieved from it.\n",
    "\n",
    "MySQL and PostgreSQL are examples of relational databases.  For the purposes of an Insight project, you can use either one.\n",
    "\n",
    "Why would you use a relational database instead of a csv or two?\n",
    "\n",
    "**A few reasons:**\n",
    "\n",
    "- They scale easily\n",
    "\n",
    "-  They are easy to query\n",
    "\n",
    "- Itâ€™s possible to do transactions in those cases where you need to write to a database, not just read from it\n",
    "\n",
    "- Everyone in industry uses them, so you should get familiar with them, too.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What does a relational database look like? ***\n",
    "\n",
    "**Let's setup PostgreSQL**\n",
    "\n",
    "We can take a look.  First we need to set up a few things. The first thing we want to do is to get a PostgreSQL server up and running.  Go to http://postgresapp.com/ and follow the three steps listed in the Quick Installation Guide. (If you aren't running a Mac, you can download PostgreSQL at http://www.postgresql.org/) \n",
    "    -- you can also use homebrew, but your path will change below --\n",
    "    \n",
    "**If you're on a mac, you might need to add psql to PATH**:<br>\n",
    "\n",
    "**Edit your .bash_profile in your home directory. Since you already installed Anaconda, it should look something like:**<br>\n",
    "```export PATH=\"/Users/YOUR_USER_NAME/anaconda/bin:$PATH\"```\n",
    "\n",
    "**Change it to look like:**<br>\n",
    "\n",
    "```export PATH=\"/Applications/Postgres.app/Contents/Versions/latest/bin:/Users/YOUR_USER_NAME/anaconda/bin:$PATH\"```\n",
    "\n",
    "**Save and reload the bash profile**<br>\n",
    "```$ source .bash_profile```\n",
    "\n",
    "**The only user right now for PSQL is 'postgres', you can make your database and enter it with that username**<br>\n",
    "```$ createdb birth_db -U postgres```<br>\n",
    "```$ psql birth_db```\n",
    "\n",
    "**If you want to make a new user for this database you can make one now. \n",
    "Note: username in the below line must match your Mac/Linux username:**<br>\n",
    "```CREATE USER username SUPERUSER PASSWORD 'yourpassword'```<br>\n",
    "\n",
    "**Exit out of PSQL (\\q) and test logging in through this user:**<br>\n",
    "```$ psql birth_db -h localhost -U username```<br>\n",
    "```$ \\c ```  (once in PSQL to check how you're logged in)<br>\n",
    "\n",
    "We'll come back to PostgreSQL in a moment.  First, we'll set up SQLAlchemy. To get started we need to install two packages into the environment that might not be installed. Run the cell below or enter the commands (without !) into the command line. \n",
    "\n",
    "Note that if you did an Anaconda installation, sqlalchemy_utils is only available through pip, and if you didn't install pip into your environment (dev_setups_conda-part1.html) you will run into problems. Also, you need to install psycopg2 using conda, otherwise you will probably run into different problems. If you mainly installed packages using pip, change the next commands to reflect that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy_utils \n",
    "!conda install psycopg2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) If Postgres isn't launched on startup \n",
    "\n",
    "**To have launchd start postgresql at login: **<br>\n",
    "```ln -sfv /usr/local/opt/postgresql/*.plist ~/Library/LaunchAgents``` <br><br>\n",
    "**Then to load postgresql now: **<br>\n",
    "```launchctl load ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist``` <br><br>\n",
    "**Or, if you don't want/need launchctl, you can just run: **<br>\n",
    "```postgres -D /usr/local/var/postgres``` <br>\n",
    "**into the command line and also look at [this page](http://postgresguide.com/) for more details.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfacing with PSQL through python\n",
    "\n",
    "Update your username and password in the cell below. Then run each cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In Python: Define your username and password used above. I've defined the database name (we're \n",
    "#using a dataset on births, so I call it birth_db). \n",
    "dbname = 'birth_db'\n",
    "username = 'username'\n",
    "pswd = 'yourpassword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print 'postgresql://%s:%s@localhost/%s'%(username,pswd,dbname)\n",
    "print engine.url\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "print engine.url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a database from the included CSV\n",
    "birth_data = pd.DataFrame.from_csv('births2012_downsampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "## df is any pandas dataframe \n",
    "birth_data.to_sql('birth_data_table', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line (to_sql) is doing a lot of heavy lifting.  It's reading a dataframe, it's creating a table, and adding the data to the table.  So ** SQLAlchemy is quite useful! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this works outside of python:\n",
    "\n",
    "** open up the PostgreSQL app, click on the \"Open psql\" button in the bottom right corner, ** <br>\n",
    "or alternatively type <br>\n",
    "```$ psql birth_db -h localhost -U username``` <br> \n",
    "into the command line  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type the following into the terminal that opens up**\n",
    "\n",
    "`$ \\c birth_db`\n",
    "\n",
    "**You should see something like the following**\n",
    "\n",
    "`$ You are now connected to database \"birth_db\" as user \"username\".`\n",
    "\n",
    "\n",
    "\n",
    "**Then try the following query:**\n",
    "\n",
    "`$ SELECT * FROM birth_data_table;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can see the table we created!  But it's kinda ugly and hard to read (type 'q' in terminal to end long output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can try a few other sample queries.  Before you type in each one, ask yourself what you think the output will look like:**\n",
    "\n",
    "`SELECT * FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(infant_sex) FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(gestation_weeks), infant_sex FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks, infant_sex;`\n",
    "\n",
    "`SELECT gestation_weeks, COUNT(gestation_weeks) FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now try the same queries, but in python!\n",
    "\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)\n",
    "\n",
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM birth_data_table WHERE delivery_method='Cesarean';\n",
    "\"\"\"\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is one method of querying the data faster than the other?  Probably not for the amount of data you can fit on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print total\n",
    "\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "birth_data = pd.DataFrame.from_csv('births2012_downsampled.csv')\n",
    "\n",
    "t0 = time.time()\n",
    "birth_data=birth_data.loc[(birth_data['delivery_method'] == 'Cesarean')]\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print total\n",
    "\n",
    "birth_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This should have given you a quick taste of how to use SQLALchemy, as well as how to run a few SQL queries both at the command line and in python.  You can see that pandas is actually a little faster than PostgreSQL here - that is because of the extra time it takes to communicate between python and PostGreSQL.  But as your database gets bigger (and certainly when it's too large to store in memory), working with relational databases becomes a necessity.**\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_insight_env]",
   "language": "python",
   "name": "conda-env-my_insight_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
